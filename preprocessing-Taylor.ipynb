{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('data/goemotions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_cols = ['admiration',\n",
    "       'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion',\n",
    "       'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust',\n",
    "       'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy',\n",
    "       'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief',\n",
    "       'remorse', 'sadness', 'surprise', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_categories = {'admiration': 'Positive', # Proposed simplified classification\n",
    "                      'amusement':'Positive',\n",
    "                      'anger':'Negative',\n",
    "                      'annoyance':'Negative',\n",
    "                      'approval':'Positive',\n",
    "                      'caring':'Positive',\n",
    "                      'confusion':'Neutral',\n",
    "                      'curiosity':'Positive',\n",
    "                      'desire':'Positive',\n",
    "                      'disappointment':'Negative',\n",
    "                      'disapproval':'Negative',\n",
    "                      'disgust':'Negative',\n",
    "                      'embarrassment':'Neutral',\n",
    "                      'excitement':'Positive',\n",
    "                      'fear':'Negative',\n",
    "                      'gratitude':'Positive',\n",
    "                      'grief':'Negative',\n",
    "                      'joy':'Positive',\n",
    "                      'love':'Positive',\n",
    "                      'nervousness':'Neutral',\n",
    "                      'optimism':'Positive',\n",
    "                      'pride':'Positive',\n",
    "                      'realization':'Neutral',\n",
    "                      'relief':'Positive',\n",
    "                      'remorse':'Negative',\n",
    "                      'sadness':'Negative',\n",
    "                      'surprise':'Neutral',\n",
    "                      'neutral':'Neutral'\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_groups = {'admiration': 1, \n",
    "                      'amusement':2,\n",
    "                      'anger':3,\n",
    "                      'annoyance':4,\n",
    "                      'approval':5,\n",
    "                      'caring':6,\n",
    "                      'confusion':7,\n",
    "                      'curiosity':8,\n",
    "                      'desire':9,\n",
    "                      'disappointment':10,\n",
    "                      'disapproval':11,\n",
    "                      'disgust':12,\n",
    "                      'embarrassment':13,\n",
    "                      'excitement':14,\n",
    "                      'fear':15,\n",
    "                      'gratitude':16,\n",
    "                      'grief':17,\n",
    "                      'joy':18,\n",
    "                      'love':19,\n",
    "                      'nervousness':20,\n",
    "                      'optimism':21,\n",
    "                      'pride':22,\n",
    "                      'realization':23,\n",
    "                      'relief':24,\n",
    "                      'remorse':25,\n",
    "                      'sadness':26,\n",
    "                      'surprise':27,\n",
    "                      'neutral':28\n",
    "                       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text       id  \\\n",
       "0                                    That game hurt.  eew5j0j   \n",
       "1     You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "2                                 Man I love reddit.  eeibobj   \n",
       "3  [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "4  Right? Considering it’s such an important docu...  eespn2i   \n",
       "\n",
       "                author            subreddit    link_id   parent_id  \\\n",
       "0                Brdd9                  nrl  t3_ajis4z  t1_eew18eq   \n",
       "1             Labalool          confessions  t3_abru74  t1_ed2m7g7   \n",
       "2        MrsRobertshaw             facepalm  t3_ahulml   t3_ahulml   \n",
       "3  American_Fascist713  starwarsspeculation  t3_ackt2f  t1_eda65q2   \n",
       "4         ImperialBoss           TrueReddit  t3_aizyuz  t1_eesoak0   \n",
       "\n",
       "   created_utc  rater_id  example_very_unclear  sentiment  \n",
       "0   1548381039         1                 False    sadness  \n",
       "1   1546427744        37                 False    neutral  \n",
       "2   1547965054        18                 False       love  \n",
       "3   1546668601         2                 False    neutral  \n",
       "4   1548280208        61                 False  gratitude  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>id</th>\n      <th>author</th>\n      <th>subreddit</th>\n      <th>link_id</th>\n      <th>parent_id</th>\n      <th>created_utc</th>\n      <th>rater_id</th>\n      <th>example_very_unclear</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>That game hurt.</td>\n      <td>eew5j0j</td>\n      <td>Brdd9</td>\n      <td>nrl</td>\n      <td>t3_ajis4z</td>\n      <td>t1_eew18eq</td>\n      <td>1548381039</td>\n      <td>1</td>\n      <td>False</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>You do right, if you don't care then fuck 'em!</td>\n      <td>ed2mah1</td>\n      <td>Labalool</td>\n      <td>confessions</td>\n      <td>t3_abru74</td>\n      <td>t1_ed2m7g7</td>\n      <td>1546427744</td>\n      <td>37</td>\n      <td>False</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Man I love reddit.</td>\n      <td>eeibobj</td>\n      <td>MrsRobertshaw</td>\n      <td>facepalm</td>\n      <td>t3_ahulml</td>\n      <td>t3_ahulml</td>\n      <td>1547965054</td>\n      <td>18</td>\n      <td>False</td>\n      <td>love</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n      <td>eda6yn6</td>\n      <td>American_Fascist713</td>\n      <td>starwarsspeculation</td>\n      <td>t3_ackt2f</td>\n      <td>t1_eda65q2</td>\n      <td>1546668601</td>\n      <td>2</td>\n      <td>False</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Right? Considering it’s such an important docu...</td>\n      <td>eespn2i</td>\n      <td>ImperialBoss</td>\n      <td>TrueReddit</td>\n      <td>t3_aizyuz</td>\n      <td>t1_eesoak0</td>\n      <td>1548280208</td>\n      <td>61</td>\n      <td>False</td>\n      <td>gratitude</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "df = df_raw.set_index(['text', 'id', 'author', 'subreddit', 'link_id', 'parent_id',\n",
    "       'created_utc', 'rater_id', 'example_very_unclear'])\n",
    "\n",
    "df = df[df==1].stack().reset_index().drop(0,1).rename(columns = {'level_9': 'sentiment'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                text       id  \\\n",
       "0                                    That game hurt.  eew5j0j   \n",
       "1     You do right, if you don't care then fuck 'em!  ed2mah1   \n",
       "2                                 Man I love reddit.  eeibobj   \n",
       "3  [NAME] was nowhere near them, he was by the Fa...  eda6yn6   \n",
       "4  Right? Considering it’s such an important docu...  eespn2i   \n",
       "\n",
       "                author            subreddit    link_id   parent_id  \\\n",
       "0                Brdd9                  nrl  t3_ajis4z  t1_eew18eq   \n",
       "1             Labalool          confessions  t3_abru74  t1_ed2m7g7   \n",
       "2        MrsRobertshaw             facepalm  t3_ahulml   t3_ahulml   \n",
       "3  American_Fascist713  starwarsspeculation  t3_ackt2f  t1_eda65q2   \n",
       "4         ImperialBoss           TrueReddit  t3_aizyuz  t1_eesoak0   \n",
       "\n",
       "   created_utc  rater_id  example_very_unclear  sentiment  sentiment_rating  \\\n",
       "0   1548381039         1                 False    sadness                -1   \n",
       "1   1546427744        37                 False    neutral                 0   \n",
       "2   1547965054        18                 False       love                 1   \n",
       "3   1546668601         2                 False    neutral                 0   \n",
       "4   1548280208        61                 False  gratitude                 1   \n",
       "\n",
       "   group  \n",
       "0     26  \n",
       "1     28  \n",
       "2     19  \n",
       "3     28  \n",
       "4     16  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>id</th>\n      <th>author</th>\n      <th>subreddit</th>\n      <th>link_id</th>\n      <th>parent_id</th>\n      <th>created_utc</th>\n      <th>rater_id</th>\n      <th>example_very_unclear</th>\n      <th>sentiment</th>\n      <th>sentiment_rating</th>\n      <th>group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>That game hurt.</td>\n      <td>eew5j0j</td>\n      <td>Brdd9</td>\n      <td>nrl</td>\n      <td>t3_ajis4z</td>\n      <td>t1_eew18eq</td>\n      <td>1548381039</td>\n      <td>1</td>\n      <td>False</td>\n      <td>sadness</td>\n      <td>-1</td>\n      <td>26</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>You do right, if you don't care then fuck 'em!</td>\n      <td>ed2mah1</td>\n      <td>Labalool</td>\n      <td>confessions</td>\n      <td>t3_abru74</td>\n      <td>t1_ed2m7g7</td>\n      <td>1546427744</td>\n      <td>37</td>\n      <td>False</td>\n      <td>neutral</td>\n      <td>0</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Man I love reddit.</td>\n      <td>eeibobj</td>\n      <td>MrsRobertshaw</td>\n      <td>facepalm</td>\n      <td>t3_ahulml</td>\n      <td>t3_ahulml</td>\n      <td>1547965054</td>\n      <td>18</td>\n      <td>False</td>\n      <td>love</td>\n      <td>1</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n      <td>eda6yn6</td>\n      <td>American_Fascist713</td>\n      <td>starwarsspeculation</td>\n      <td>t3_ackt2f</td>\n      <td>t1_eda65q2</td>\n      <td>1546668601</td>\n      <td>2</td>\n      <td>False</td>\n      <td>neutral</td>\n      <td>0</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Right? Considering it’s such an important docu...</td>\n      <td>eespn2i</td>\n      <td>ImperialBoss</td>\n      <td>TrueReddit</td>\n      <td>t3_aizyuz</td>\n      <td>t1_eesoak0</td>\n      <td>1548280208</td>\n      <td>61</td>\n      <td>False</td>\n      <td>gratitude</td>\n      <td>1</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "df['sentiment_rating'] = df['sentiment'].map(emotion_categories).map({ 'Negative': -1, \"Neutral\": 0, \"Positive\": 1})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    name   sentiment   n  group                     id\n",
       "0           2meirl4meirl     sadness  70     26           2meirl4meirl\n",
       "1                  49ers  admiration  50      1                  49ers\n",
       "2           4PanelCringe   amusement  73      2           4PanelCringe\n",
       "3            90DayFiance  admiration  76      1            90DayFiance\n",
       "4  90dayfianceuncensored    approval  63      5  90dayfianceuncensored"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>sentiment</th>\n      <th>n</th>\n      <th>group</th>\n      <th>id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2meirl4meirl</td>\n      <td>sadness</td>\n      <td>70</td>\n      <td>26</td>\n      <td>2meirl4meirl</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49ers</td>\n      <td>admiration</td>\n      <td>50</td>\n      <td>1</td>\n      <td>49ers</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4PanelCringe</td>\n      <td>amusement</td>\n      <td>73</td>\n      <td>2</td>\n      <td>4PanelCringe</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>90DayFiance</td>\n      <td>admiration</td>\n      <td>76</td>\n      <td>1</td>\n      <td>90DayFiance</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>90dayfianceuncensored</td>\n      <td>approval</td>\n      <td>63</td>\n      <td>5</td>\n      <td>90dayfianceuncensored</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Get top sentiment for each subreddit\n",
    "top_sentiment_per_subreddit = df[df['sentiment'] != 'neutral'].groupby(['subreddit', 'sentiment'], as_index = False).count().sort_values(['subreddit', 'text'], ascending = False).groupby('subreddit', as_index = False).first()[['subreddit', 'sentiment', 'text']].rename(columns = { 'text': 'n', 'subreddit': 'name'})\n",
    "\n",
    "top_sentiment_per_subreddit['group'] = top_sentiment_per_subreddit['sentiment'].map(emotion_groups)\n",
    "top_sentiment_per_subreddit['id'] = top_sentiment_per_subreddit['name']\n",
    "\n",
    "top_sentiment_per_subreddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = top_sentiment_per_subreddit.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "15468 / 249529\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7b4b1d3de4ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlinks_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m \u001b[0;34m'source'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subreddit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msubreddit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mclear_output\u001b[0;34m(wait)\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteractiveshell\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mInteractiveShell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m         \u001b[0mInteractiveShell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_pub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1435\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\033[2K\\r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/ipykernel/zmqshell.py\u001b[0m in \u001b[0;36mclear_output\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    158\u001b[0m         self.session.send(\n\u001b[1;32m    159\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'clear_output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         )\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, stream, msg_or_type, content, parent, ident, buffers, track, header, metadata)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madapt_version\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         \u001b[0mto_send\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    738\u001b[0m         \u001b[0mto_send\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m         \u001b[0mlongest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mto_send\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mserialize\u001b[0;34m(self, msg, ident)\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Content incorrect type: %s\"\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         real_message = [self.pack(msg['header']),\n\u001b[0m\u001b[1;32m    636\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'parent_header'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# disallow nan, because it's not actually valid JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m json_packer = lambda obj: jsonapi.dumps(obj, default=date_default,\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mensure_ascii\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    105\u001b[0m \u001b[0mjson_unpacker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mjsonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/zmq/utils/jsonapi.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(o, **kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'separators'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m':'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjsonmod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/jupyter_client/jsonutil.py\u001b[0m in \u001b[0;36mdate_default\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mdate_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0;34m\"\"\"default function for packing datetime objects in JSON.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# graph links\n",
    "links_data = []\n",
    "for index, row in df.iterrows():\n",
    "    author = row['author']\n",
    "    other_posts = df[(df['id'] != row['id']) & (df['author'] == author)]\n",
    "    other_subreddits = list(set(other_posts['subreddit']))\n",
    "    for subreddit in other_subreddits:\n",
    "        links_data.append({ 'source': row['subreddit'], 'target': subreddit, 'count': 1})\n",
    "    \n",
    "    clear_output()\n",
    "    print(index, \"/\", len(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                    source                 target  count\n",
       "338  90dayfianceuncensored                 tennis      7\n",
       "339  90dayfianceuncensored  terriblefacebookmemes      7\n",
       "340  90dayfianceuncensored                  texas      7\n",
       "341  90dayfianceuncensored           thatHappened      7\n",
       "342  90dayfianceuncensored                   tifu      7\n",
       "343  90dayfianceuncensored           timberwolves      7\n",
       "344  90dayfianceuncensored         torontoraptors      7\n",
       "345  90dayfianceuncensored   traaaaaaannnnnnnnnns      7\n",
       "346  90dayfianceuncensored                  trees      7\n",
       "347  90dayfianceuncensored             truegaming      7\n",
       "348  90dayfianceuncensored            uberdrivers      7\n",
       "349  90dayfianceuncensored             ukpolitics      7\n",
       "350  90dayfianceuncensored          unitedkingdom      7\n",
       "351  90dayfianceuncensored       unpopularopinion      7\n",
       "352  90dayfianceuncensored              vancouver      7\n",
       "353  90dayfianceuncensored        vanderpumprules      7\n",
       "354  90dayfianceuncensored                  vegan      7\n",
       "355  90dayfianceuncensored        vegancirclejerk      7\n",
       "356  90dayfianceuncensored                 videos      7\n",
       "357  90dayfianceuncensored                walmart      7\n",
       "358  90dayfianceuncensored           washingtondc      7\n",
       "359  90dayfianceuncensored                   weed      7\n",
       "360  90dayfianceuncensored         wholesomememes      7\n",
       "361  90dayfianceuncensored             wildhockey      7\n",
       "362  90dayfianceuncensored                woooosh      7\n",
       "363  90dayfianceuncensored          worldpolitics      7\n",
       "364  90dayfianceuncensored         yesyesyesyesno      7\n",
       "365  90dayfianceuncensored      youseeingthisshit      7\n",
       "366  90dayfianceuncensored                youtube      7\n",
       "99   90dayfianceuncensored               JustNoSO      2\n",
       "13             90DayFiance            90DayFiance     11\n",
       "19             90DayFiance        loveafterlockup      4\n",
       "14             90DayFiance  90dayfianceuncensored      2\n",
       "15             90DayFiance            My600lbLife      1\n",
       "16             90DayFiance              SeattleWA      1\n",
       "17             90DayFiance       ShitPoliticsSays      1\n",
       "18             90DayFiance                antiMLM      1\n",
       "9             4PanelCringe        TownofSalemgame      6\n",
       "10            4PanelCringe            gatekeeping      2\n",
       "11            4PanelCringe             raimimemes      1\n",
       "12            4PanelCringe                   rant      1\n",
       "7                    49ers                  49ers     10\n",
       "8                    49ers              teenagers      2\n",
       "0             2meirl4meirl           2meirl4meirl      6\n",
       "2             2meirl4meirl                 AskMen      3\n",
       "3             2meirl4meirl           SuicideWatch      3\n",
       "5             2meirl4meirl         lostgeneration      2\n",
       "1             2meirl4meirl      AnimalsBeingJerks      1\n",
       "4             2meirl4meirl           antinatalism      1\n",
       "6             2meirl4meirl                    nba      1"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>source</th>\n      <th>target</th>\n      <th>count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>338</th>\n      <td>90dayfianceuncensored</td>\n      <td>tennis</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>339</th>\n      <td>90dayfianceuncensored</td>\n      <td>terriblefacebookmemes</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>340</th>\n      <td>90dayfianceuncensored</td>\n      <td>texas</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>341</th>\n      <td>90dayfianceuncensored</td>\n      <td>thatHappened</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>90dayfianceuncensored</td>\n      <td>tifu</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>343</th>\n      <td>90dayfianceuncensored</td>\n      <td>timberwolves</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>344</th>\n      <td>90dayfianceuncensored</td>\n      <td>torontoraptors</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>345</th>\n      <td>90dayfianceuncensored</td>\n      <td>traaaaaaannnnnnnnnns</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>346</th>\n      <td>90dayfianceuncensored</td>\n      <td>trees</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>347</th>\n      <td>90dayfianceuncensored</td>\n      <td>truegaming</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>348</th>\n      <td>90dayfianceuncensored</td>\n      <td>uberdrivers</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>349</th>\n      <td>90dayfianceuncensored</td>\n      <td>ukpolitics</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>350</th>\n      <td>90dayfianceuncensored</td>\n      <td>unitedkingdom</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>351</th>\n      <td>90dayfianceuncensored</td>\n      <td>unpopularopinion</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>352</th>\n      <td>90dayfianceuncensored</td>\n      <td>vancouver</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>353</th>\n      <td>90dayfianceuncensored</td>\n      <td>vanderpumprules</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>354</th>\n      <td>90dayfianceuncensored</td>\n      <td>vegan</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>355</th>\n      <td>90dayfianceuncensored</td>\n      <td>vegancirclejerk</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>356</th>\n      <td>90dayfianceuncensored</td>\n      <td>videos</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>357</th>\n      <td>90dayfianceuncensored</td>\n      <td>walmart</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>358</th>\n      <td>90dayfianceuncensored</td>\n      <td>washingtondc</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>90dayfianceuncensored</td>\n      <td>weed</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>90dayfianceuncensored</td>\n      <td>wholesomememes</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>90dayfianceuncensored</td>\n      <td>wildhockey</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>362</th>\n      <td>90dayfianceuncensored</td>\n      <td>woooosh</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>363</th>\n      <td>90dayfianceuncensored</td>\n      <td>worldpolitics</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>364</th>\n      <td>90dayfianceuncensored</td>\n      <td>yesyesyesyesno</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>365</th>\n      <td>90dayfianceuncensored</td>\n      <td>youseeingthisshit</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>366</th>\n      <td>90dayfianceuncensored</td>\n      <td>youtube</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>99</th>\n      <td>90dayfianceuncensored</td>\n      <td>JustNoSO</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>90DayFiance</td>\n      <td>90DayFiance</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>90DayFiance</td>\n      <td>loveafterlockup</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>90DayFiance</td>\n      <td>90dayfianceuncensored</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>90DayFiance</td>\n      <td>My600lbLife</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>90DayFiance</td>\n      <td>SeattleWA</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>90DayFiance</td>\n      <td>ShitPoliticsSays</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>90DayFiance</td>\n      <td>antiMLM</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4PanelCringe</td>\n      <td>TownofSalemgame</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4PanelCringe</td>\n      <td>gatekeeping</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>4PanelCringe</td>\n      <td>raimimemes</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>4PanelCringe</td>\n      <td>rant</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>49ers</td>\n      <td>49ers</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>49ers</td>\n      <td>teenagers</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>2meirl4meirl</td>\n      <td>2meirl4meirl</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2meirl4meirl</td>\n      <td>AskMen</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2meirl4meirl</td>\n      <td>SuicideWatch</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2meirl4meirl</td>\n      <td>lostgeneration</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2meirl4meirl</td>\n      <td>AnimalsBeingJerks</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2meirl4meirl</td>\n      <td>antinatalism</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>2meirl4meirl</td>\n      <td>nba</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 57
    }
   ],
   "source": [
    "links_df = pd.DataFrame(links_data).groupby(['source', 'target'], as_index = False).count().sort_values(['source', 'count'], ascending = False)\n",
    "# .groupby(['source']).head(20)[['source', 'target']]\n",
    "# links_df['value'] = 1\n",
    "links_df.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = links_df.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "arc_diagram_graph = {\n",
    "    'nodes': nodes,\n",
    "    'links': links\n",
    "}\n",
    "\n",
    "with open('arc-data.json', 'w') as fout:\n",
    "    json.dump(arc_diagram_graph , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Network graph\n",
    "df_users = df[['author', 'rater_id', 'subreddit', 'sentiment_rating']]\n",
    "user_nodes = df_users.groupby(['author'], as_index = False).agg({ 'sentiment_rating': 'mean', 'subreddit': 'nunique'}).rename(columns = {'subreddit': 'connections', 'author': 'name'})\n",
    "user_nodes['type'] = 'user'\n",
    "user_nodes = user_nodes.to_dict('records')\n",
    "\n",
    "subreddit_nodes = df_users.groupby(['subreddit'], as_index = False).agg({ 'sentiment_rating': 'mean', 'author': 'nunique'}).rename(columns = {'author': 'connections', 'subreddit': 'name'})\n",
    "subreddit_nodes['type'] = 'subreddit'\n",
    "subreddit_nodes = subreddit_nodes.to_dict('records')\n",
    "\n",
    "with open('nodes.json', 'w') as fout:\n",
    "    json.dump(user_nodes + subreddit_nodes , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "authors_and_subreddits = df_users[['author', \"subreddit\"]].drop_duplicates(keep = \"first\")\n",
    "subreddits = authors_and_subreddits['subreddit'].drop_duplicates(keep = \"first\")\n",
    "\n",
    "links = []\n",
    "\n",
    "for subreddit in subreddits:\n",
    "    authors = authors_and_subreddits[authors_and_subreddits['subreddit'] == subreddit]['author'].to_list()\n",
    "    for author in authors:\n",
    "        links.append({ 'source': subreddit, 'target': author})\n",
    "\n",
    "with open('links.json', 'w') as fout:\n",
    "    json.dump(links , fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "51833"
      ]
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "49150"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "len(authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw.groupby(['id', 'subreddit', 'text'])[emotions_cols].sum().reset_index() # Aggregates by post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf['max_val'] = df[emotions_cols].max(axis=1)\\nfor col in emotions_cols:\\n    df[col] = df[col] - df['max_val']\\ndel df['max_val']\\ndf_new = (df.melt(['id', 'subreddit'], var_name='emotion').query('value >= 0')\\n       .groupby(['id', 'subreddit'])['emotion']\\n       .apply(', '.join)\\n       .reset_index())\\ndf_grouped = df_new.groupby(['subreddit', 'emotion']).count().reset_index()\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only keeps emotion(s) with the most votes for each post\n",
    "\"\"\"\n",
    "df['max_val'] = df[emotions_cols].max(axis=1)\n",
    "for col in emotions_cols:\n",
    "    df[col] = df[col] - df['max_val']\n",
    "del df['max_val']\n",
    "df_new = (df.melt(['id', 'subreddit'], var_name='emotion').query('value >= 0')\n",
    "       .groupby(['id', 'subreddit'])['emotion']\n",
    "       .apply(', '.join)\n",
    "       .reset_index())\n",
    "df_grouped = df_new.groupby(['subreddit', 'emotion']).count().reset_index()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>farcry</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>...</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shieldbro</th>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anticonsumption</th>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSBM</th>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>darknet</th>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vanderpumprules</th>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>...</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AnimalsBeingBros</th>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>...</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "      <td>231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>socialanxiety</th>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>...</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cringe</th>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>...</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loveafterlockup</th>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>...</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id  text  admiration  amusement  anger  annoyance  \\\n",
       "subreddit                                                              \n",
       "farcry             25    25          25         25     25         25   \n",
       "shieldbro          32    32          32         32     32         32   \n",
       "Anticonsumption    34    34          34         34     34         34   \n",
       "SSBM               35    35          35         35     35         35   \n",
       "darknet            38    38          38         38     38         38   \n",
       "...               ...   ...         ...        ...    ...        ...   \n",
       "vanderpumprules   221   221         221        221    221        221   \n",
       "AnimalsBeingBros  231   231         231        231    231        231   \n",
       "socialanxiety     232   232         232        232    232        232   \n",
       "cringe            239   239         239        239    239        239   \n",
       "loveafterlockup   241   241         241        241    241        241   \n",
       "\n",
       "                  approval  caring  confusion  curiosity  ...  love  \\\n",
       "subreddit                                                 ...         \n",
       "farcry                  25      25         25         25  ...    25   \n",
       "shieldbro               32      32         32         32  ...    32   \n",
       "Anticonsumption         34      34         34         34  ...    34   \n",
       "SSBM                    35      35         35         35  ...    35   \n",
       "darknet                 38      38         38         38  ...    38   \n",
       "...                    ...     ...        ...        ...  ...   ...   \n",
       "vanderpumprules        221     221        221        221  ...   221   \n",
       "AnimalsBeingBros       231     231        231        231  ...   231   \n",
       "socialanxiety          232     232        232        232  ...   232   \n",
       "cringe                 239     239        239        239  ...   239   \n",
       "loveafterlockup        241     241        241        241  ...   241   \n",
       "\n",
       "                  nervousness  optimism  pride  realization  relief  remorse  \\\n",
       "subreddit                                                                      \n",
       "farcry                     25        25     25           25      25       25   \n",
       "shieldbro                  32        32     32           32      32       32   \n",
       "Anticonsumption            34        34     34           34      34       34   \n",
       "SSBM                       35        35     35           35      35       35   \n",
       "darknet                    38        38     38           38      38       38   \n",
       "...                       ...       ...    ...          ...     ...      ...   \n",
       "vanderpumprules           221       221    221          221     221      221   \n",
       "AnimalsBeingBros          231       231    231          231     231      231   \n",
       "socialanxiety             232       232    232          232     232      232   \n",
       "cringe                    239       239    239          239     239      239   \n",
       "loveafterlockup           241       241    241          241     241      241   \n",
       "\n",
       "                  sadness  surprise  neutral  \n",
       "subreddit                                     \n",
       "farcry                 25        25       25  \n",
       "shieldbro              32        32       32  \n",
       "Anticonsumption        34        34       34  \n",
       "SSBM                   35        35       35  \n",
       "darknet                38        38       38  \n",
       "...                   ...       ...      ...  \n",
       "vanderpumprules       221       221      221  \n",
       "AnimalsBeingBros      231       231      231  \n",
       "socialanxiety         232       232      232  \n",
       "cringe                239       239      239  \n",
       "loveafterlockup       241       241      241  \n",
       "\n",
       "[483 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['subreddit']).count().sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_df = pd.DataFrame(columns = ['subreddit', 'emotion', 'count'])\n",
    "for emotion in emotions_cols:\n",
    "    gp_df = df.groupby(['subreddit'])[emotion].sum()\n",
    "    d = {'subreddit': gp_df.index, 'emotion': [emotion]*len(gp_df), 'count':gp_df.values}\n",
    "    subreddit_df = subreddit_df.append(pd.DataFrame(data = d), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hv.extension('bokeh')\n",
    "#hv.Sankey(subreddit_df.loc[lambda f: f['subreddit'] == 'socialanxiety'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subreddit_df.to_csv('subreddit_emotion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_df = pd.DataFrame(columns = ['subreddit', 'emotion', 'text'])\n",
    "for emotion in emotions_cols:\n",
    "    df_long = df[df['text'].str.split().str.len().ge(4)] # Remove short posts\n",
    "    df_sorted = df_long.sort_values(emotion, ascending=False)\n",
    "    gp_df = df_sorted.groupby('subreddit').first()\n",
    "    d = {'subreddit': gp_df.index, 'emotion': [emotion]*len(gp_df), 'text':gp_df['text']}\n",
    "    text_df = text_df.append(pd.DataFrame(data = d), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(text_df, subreddit_df, how='left', on=['subreddit', 'emotion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.columns = ['source', 'target', 'text', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('subreddit_emotion_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2meirl4meirl</td>\n",
       "      <td>admiration</td>\n",
       "      <td>Or embalmed! Green burial is the best burial</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49ers</td>\n",
       "      <td>admiration</td>\n",
       "      <td>Can we please just call out defense next year ...</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4PanelCringe</td>\n",
       "      <td>admiration</td>\n",
       "      <td>Seriously. [NAME] is a hero. I heard he was a ...</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90DayFiance</td>\n",
       "      <td>admiration</td>\n",
       "      <td>maybe. Id praise her for it though. In a world...</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90dayfianceuncensored</td>\n",
       "      <td>admiration</td>\n",
       "      <td>She could and should pursue modeling! It seeme...</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13519</th>\n",
       "      <td>worldpolitics</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The original video was debunked. Do you agree ...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13520</th>\n",
       "      <td>yesyesyesyesno</td>\n",
       "      <td>neutral</td>\n",
       "      <td>This is like 4 years old from vine</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13521</th>\n",
       "      <td>youseeingthisshit</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Imagine being upset over who someone loves.</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13522</th>\n",
       "      <td>youtube</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Naming comes from the heart</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13523</th>\n",
       "      <td>youtubehaiku</td>\n",
       "      <td>neutral</td>\n",
       "      <td>I’m doing my part!</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13524 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   subreddit     emotion  \\\n",
       "0               2meirl4meirl  admiration   \n",
       "1                      49ers  admiration   \n",
       "2               4PanelCringe  admiration   \n",
       "3                90DayFiance  admiration   \n",
       "4      90dayfianceuncensored  admiration   \n",
       "...                      ...         ...   \n",
       "13519          worldpolitics     neutral   \n",
       "13520         yesyesyesyesno     neutral   \n",
       "13521      youseeingthisshit     neutral   \n",
       "13522                youtube     neutral   \n",
       "13523           youtubehaiku     neutral   \n",
       "\n",
       "                                                    text count  \n",
       "0           Or embalmed! Green burial is the best burial    47  \n",
       "1      Can we please just call out defense next year ...    50  \n",
       "2      Seriously. [NAME] is a hero. I heard he was a ...    52  \n",
       "3      maybe. Id praise her for it though. In a world...    76  \n",
       "4      She could and should pursue modeling! It seeme...    43  \n",
       "...                                                  ...   ...  \n",
       "13519  The original video was debunked. Do you agree ...   156  \n",
       "13520                 This is like 4 years old from vine   198  \n",
       "13521        Imagine being upset over who someone loves.   198  \n",
       "13522                        Naming comes from the heart    95  \n",
       "13523                                 I’m doing my part!    70  \n",
       "\n",
       "[13524 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python376jvsc74a57bd055cbe3d41f8f12bd0dbfbf5dfc94736b18500205abeb437c61b08d02033e2eff",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}